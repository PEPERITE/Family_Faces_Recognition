{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating more faces with Keras generator\n",
    "for data set augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Data Augmentation (after Tyler's course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_maintain_aspect_ratio(input_image_path, target_size):\n",
    "    image = Image.open(input_image_path)\n",
    "    width, height = image.size\n",
    "    \n",
    "    w_pad = 0\n",
    "    h_pad = 0\n",
    "    bonus_h_pad = 0\n",
    "    bonus_w_pad = 0\n",
    "    \n",
    "    if width > height:\n",
    "        pix_diff = (width - height)\n",
    "        h_pad = pix_diff // 2\n",
    "        bonus_h_pad = pix_diff % 2 # If the difference was odd, add one pixel on one side.\n",
    "    elif height > width:\n",
    "        pix_diff = (height - width)\n",
    "        w_pad = pix_diff // 2\n",
    "        bonus_w_pad = pix_diff % 2 # If the difference was odd, add one pixel on one side.\n",
    "    # else: image is already square. Both pads stay 0\n",
    "    \n",
    "    image = ImageOps.expand(image, (w_pad, h_pad, w_pad+bonus_w_pad, h_pad+bonus_h_pad))\n",
    "    image = image.resize(target_size)\n",
    "    \n",
    "    image_data = np.array(image.getdata()).reshape(image.size[0], image.size[1], 3)\n",
    "    \n",
    "    return np.divide(image_data, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, repeat for each family member adapting the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_location = '.\\\\Faces_extracted_family_QCed\\\\_EVA\\\\'\n",
    "path_to_write='.\\\\Faces_extracted_family_QCed\\\\_EVA_GENERATED\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in os.listdir(photo_location):\n",
    "    if name.startswith('.'): continue # Avoid looking at hidden files, which the OS sometimes puts in the folder\n",
    "    image = keras_image.load_img(photo_location + name)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "# THIS WILL DISPLAY THE 50 FACES FOR 1 FAMILY MEMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([i for i in range(50)]) # This are required for flow, which we'll see soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "images = []\n",
    "for name in os.listdir(photo_location):\n",
    "    if name.startswith('.'): continue \n",
    "    \n",
    "    # Note the target_size parameter\n",
    "    image = load_maintain_aspect_ratio(photo_location + name, target_size=(96, 96))\n",
    "    image = denoise_bilateral(image,multichannel=True) # applying a filter\n",
    "    images.append(image)\n",
    "images=np.array(images)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[49])\n",
    "# THIS WILL CHECK ONE IMAGE RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There is 50 different original images for each person\n",
    "fig = plt.figure(figsize=(10.,10.))\n",
    "grid=ImageGrid(fig,111,nrows_ncols=(5,10), axes_pad=0.1)\n",
    "for ax, im in zip(grid,images):\n",
    "    ax.imshow(im)\n",
    "plt.show()\n",
    "# THIS WILL PLOT A GRID OF THE 50 ORIGINAL FACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance of the Generator \n",
    "datagen = ImageDataGenerator(rotation_range=25, shear_range=3, zoom_range=0.1, \n",
    "                             fill_mode='constant', horizontal_flip=True, cval=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds_max=20\n",
    "# This will generates 50x20=1000 images of the same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "round = 0\n",
    "for image_batch, label_batch in datagen.flow(images, labels, batch_size=50):\n",
    "    for image, label in zip(image_batch, label_batch):\n",
    "        plt.imsave(path_to_write+'generated_round%d_from_image%d.png' % (round,label),image)\n",
    "#    print(len(label_batch))\n",
    "    round += 1\n",
    "    if round >= rounds_max:\n",
    "        break # to avoid infinity..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat for each person / folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Operating System library imported\n",
    "import glob # to make operation on directory like listing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers import Input,Conv2D,MaxPooling2D,UpSampling2D\n",
    "#from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import *\n",
    "#from keras.optimizers import RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.initializers import Initializer\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.regularizers import Regularizer\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from IPython.display import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import *\n",
    "from skimage import measure\n",
    "from skimage.color import *\n",
    "from skimage.filters import *\n",
    "from skimage.util import *\n",
    "from skimage.restoration import *\n",
    "from skimage.restoration import inpaint\n",
    "from skimage.transform import *\n",
    "from skimage.segmentation import *\n",
    "from skimage.feature import *\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image library\n",
    "from skimage import data\n",
    "# list of object horse, rocket, coins..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
